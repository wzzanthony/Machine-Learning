{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.19151945 0.62210877 0.43772774]\n",
      " [0.78535858 0.77997581 0.27259261]\n",
      " [0.27646426 0.80187218 0.95813935]\n",
      " ...\n",
      " [0.77485433 0.17616405 0.88455879]\n",
      " [0.09306395 0.20218845 0.37240548]\n",
      " [0.17365571 0.34523374 0.56773848]]\n",
      "[ 9.07786127 10.68836829 16.0797263  11.12922286 10.93165403  5.37329728\n",
      " 12.21769522  6.99763629 11.92183168 11.25409795 14.79971809 12.22758633\n",
      " 10.96579249  6.1503401  10.46766117  8.55032711  5.45997705  5.8491499\n",
      " 16.33001627 18.18512486  9.92349225  3.58288103  8.83293151 11.05386043\n",
      "  5.06704001 11.94254694  6.45817975 14.56271085 11.87672677 11.83621297\n",
      "  9.58556266 12.16169141  7.54118908 14.83178201 16.95711344  7.2010966\n",
      "  9.41633216 13.36307267  8.89049525 13.53761433 16.59743526  5.81093283\n",
      "  5.94787817  8.45044079  7.09175585  8.17099288  4.67392227 15.3674629\n",
      " 10.1211939   6.69616873 10.66032044 13.32990072 15.52396023 11.07875215\n",
      " 19.80253898 11.41929488 15.69679186 12.79052379  9.04353678 15.40296188\n",
      " 14.50745991  5.85626504 10.82684019  6.46258723  6.29346456  6.11076124\n",
      " 19.33324427 17.32821695  7.57283027  7.07157768 10.187796   10.37520121\n",
      "  9.43062138  6.39246954 12.64853329  6.98462807  4.11688474 17.10762839\n",
      "  7.29038156 13.22771353  1.77970124  6.3287382   4.0317472  13.53221294\n",
      "  8.69087192 12.42392897 12.53767618 12.76175689 15.22297016 14.04727772\n",
      "  8.616245   12.60111427  8.7117879   3.84238311  9.47956126 14.8911322\n",
      "  8.14947582 18.70157352 11.12496826  8.30604101 11.48859452  7.55171731\n",
      " 14.24582487  7.62440733  2.94020209 12.60147821 16.53867848 12.26784659\n",
      " 12.49106895  1.58145023  7.53335905  8.35312782 16.01726403 17.38603735\n",
      " 13.85058557 12.81793394  9.56437868 11.94597849 13.96680295 11.35959062\n",
      "  8.89138927 12.36872469 13.87370378 11.47866185  7.38026689 13.77889773\n",
      " 10.53600207 12.70714639  5.1755306  14.16049317  5.32740025 16.36744632\n",
      "  9.57330081 13.17309885  7.97682816  7.13848392  9.37914495 17.08256052\n",
      " 16.58370831 10.8824037  17.00447988 15.34435017  8.92724986  8.04052215\n",
      " 11.45471907  8.49035479 16.31266802  4.91238327  8.81632288 10.30858435\n",
      " 17.18737034 12.41114677 12.05441828  7.84046494  9.16965441  6.63911287\n",
      "  4.44900393 14.27054657  5.17796142  9.56177954  8.06092304 14.23704375\n",
      "  6.36305329 10.55577213  7.29760177 15.36326758 13.84545457  7.51398571\n",
      "  6.18737077  7.59150763  7.45082811  3.06725252  3.23619985 17.97518396\n",
      " 13.8966688   7.87774061 13.40866891 11.16866861  8.94365227 14.04349463\n",
      "  5.70710662  2.90495664 11.06033867  6.47183888 15.72944232 14.77858947\n",
      "  3.01379814  7.26133446 11.78560762  4.47540678 14.19877081  6.04490669\n",
      "  6.52596256 15.16183336  8.60607703  8.10894149 10.60469598 12.4340502\n",
      "  8.19641355  7.86683848  9.52428868 10.63471422  5.84999185 11.13362284\n",
      " 12.03807586 14.20642003 13.30701635  9.06287704  7.5927058   6.29503364\n",
      "  6.83748614 14.1550358   3.89050322  6.86309022 11.34180739  7.81690429\n",
      "  8.653588   14.03381404  9.12136578 12.87247636 13.91368471  3.92660031\n",
      " 11.49918386 13.57872661  7.266045   13.23343461  4.51695465 10.88947142\n",
      "  9.6703235  12.30435404  5.79781909  7.51678521  5.11064867  8.74348701\n",
      "  7.52144318 15.42330473 13.08195222 17.69902463  3.95233236 13.22503427\n",
      " 12.1403755  10.2957699  14.69094853 11.76495674  8.82846793 11.47796772\n",
      " 16.90917638  7.20913035 15.59688176 10.61395437 12.19500175  7.26737684\n",
      " 14.38727016  4.90970646 17.38780676 13.8499805  10.01046353 10.44885638\n",
      " 12.28318046 11.43858545  9.31433305  9.13569732 13.15286545 15.67291545\n",
      "  7.059134    8.67174526 11.58980726 12.89134885 12.32677278  4.11751186\n",
      " 16.70218608  6.97725252  8.36580556 16.18702372  8.09229554  6.21669902\n",
      "  3.98406942  1.98196218 14.16913569  8.91632079 10.25114053  7.63008142\n",
      "  8.43121528 13.97176174 12.61543402 11.88917695  6.64408265 14.04694215\n",
      " 15.00204158 15.18389293 15.82521648 12.81690291 13.27980369 12.8437731\n",
      "  6.43473067 14.27035119  5.4526403  16.12822152 14.62087942 13.82040877\n",
      "  8.94835106 11.81700707 11.9986133   9.33416897  9.24511466 16.40475609\n",
      " 13.02131465 14.68450613 15.27679258  6.44360813  5.71296975  9.77059954\n",
      "  3.8105218   3.15587484 14.9119999  19.24217235 14.17740793  5.41669107\n",
      " 13.37314682 14.26892324  7.82425337 11.67318009 14.4771546   4.75718263\n",
      "  9.74268469 10.87269387 16.94751042 13.33386018  9.23221839  6.62370192\n",
      "  2.52853366 14.21920899 10.31141524 14.34137264 16.30216938  6.64873442\n",
      "  5.37188359 12.61177634 10.9604267   1.09988809  7.35931844 16.2175865\n",
      " 13.6684414   8.36041824  5.7772029   8.93803776  1.67842076 15.4932099\n",
      " 15.39896154 12.24330309  9.0038111  14.21214397 10.07681641  8.60155259\n",
      "  8.58035673  6.86130302  9.1453231   6.71812117  8.4273126  15.34094932\n",
      " 10.99750169 13.46709989 12.52967221  4.54192943 13.99820184  6.14951114\n",
      "  5.37476755  7.5241381   8.0100273   7.62400187  2.23269053 10.18443075\n",
      " 10.32586205 12.11134023 11.60334961 10.40338443  4.8377102  11.24398134\n",
      "  1.80999454  6.86553612  8.58169808  8.92831336  5.68473355  6.53590319\n",
      " 10.86454738 10.22698238  6.58416796 11.59687331 14.34580984  6.91268187\n",
      " 16.45453155  3.1938533  11.08694839 10.11585088 11.45350377  5.93132684\n",
      " 10.12523582 12.50005359  8.05235908 11.40820445  7.69528124 10.99800547\n",
      "  7.94707886 14.46864614 11.37516014  9.75999174  8.48222602  6.47793732\n",
      " 15.49080225 19.85328932 10.84161333 11.53964909 15.93937952  8.02325307\n",
      "  7.46809988  8.65408369 11.52905728  7.51484809 15.06917018  5.50553694\n",
      "  5.45241897 16.39477777  8.11388261 14.09355066 12.18547271 10.01100029\n",
      "  8.54996002 14.22018734  9.56864554  8.61050776  5.06333822 15.69041046\n",
      " 14.20310431 14.24074781  7.15211906  5.58081342  9.16546952  6.33297111\n",
      "  8.8284045   9.80980043  7.7805263   9.19089768 16.0185546   2.0615536\n",
      " 10.0797419   0.75048087  8.45990675 11.70503945 11.99904371  7.74981323\n",
      "  5.36557825 14.46811681 10.0957485  15.98480248 17.77061952 12.54082967\n",
      " 14.65196444  7.90290444 12.74817869  6.32518788 13.6284619  11.10327571\n",
      "  8.55884973 10.9534031   6.39979855  3.61559696 14.06951056  8.39888475\n",
      " 12.29549881  8.59204721  5.14732251  5.66267484 14.42632501 11.09256662\n",
      "  3.58985296 13.83743564 12.92581368 15.42819232 11.80182034  6.50789009\n",
      "  5.86769971  5.31620648  6.10747241  8.47060863 10.81127939 13.42070144\n",
      " 16.06476087 12.62894328  5.23980875 13.56023988 14.72669585  9.22601056\n",
      " 13.02814437 16.32149929 10.08875832  3.55205914 13.44140891 13.81175819\n",
      "  5.56532196  8.82876192]\n"
     ]
    }
   ],
   "source": [
    "#生成数据\n",
    "import numpy as np\n",
    "#生成随机数\n",
    "np.random.seed(1234)\n",
    "x = np.random.rand(500,3)\n",
    "#构建映射关系，模拟真实的数据待预测值,映射关系为y = 4.2 + 5.7*x1 + 10.8*x2，可自行设置值进行尝试\n",
    "y = x.dot(np.array([4.2,5.7,10.8]))\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "估计的参数值为：[ 4.2  5.7 10.8]\n",
      "R2:1.0\n",
      "预测值为: [85.2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 调用模型\n",
    "lr = LinearRegression(fit_intercept=True)\n",
    "# 训练模型\n",
    "lr.fit(x,y)\n",
    "print(\"估计的参数值为：%s\" %(lr.coef_))\n",
    "# 计算R平方\n",
    "print('R2:%s' %(lr.score(x,y)))\n",
    "# 任意设定变量，预测目标值\n",
    "x_test = np.array([2,4,5]).reshape(1,-1)\n",
    "y_hat = lr.predict(x_test)\n",
    "print(\"预测值为: %s\" %(y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "估计的参数值：[ 4.2  5.7 10.8]\n",
      "预测值为: [85.2]\n"
     ]
    }
   ],
   "source": [
    "#2.牛顿迭代法\n",
    "class LR_LS():\n",
    "    def __init__(self):\n",
    "        self.w = None      \n",
    "    def fit(self, X, Y):\n",
    "        # 最小二乘法矩阵求解\n",
    "        self.w = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y)\n",
    "    def predict(self, X):\n",
    "        # 用已经拟合的参数值预测新自变量\n",
    "        y_pred = X.dot(self.w)\n",
    "        return y_pred\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    lr_ls = LR_LS()\n",
    "    lr_ls.fit(x,y)\n",
    "    print(\"估计的参数值：%s\" %(lr_ls.w))\n",
    "    x_test = np.array([2,4,5]).reshape(1,-1)\n",
    "    print(\"预测值为: %s\" %(lr_ls.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "估计的参数值为：[ 4.20000001  5.70000003 10.79999997]\n",
      "预测值为：[85.19999995]\n"
     ]
    }
   ],
   "source": [
    "#3.梯度下降法\n",
    "class LR_GD():\n",
    "    def __init__(self):\n",
    "        self.w = None     \n",
    "    def fit(self,X,y,alpha=0.02,loss = 1e-10): # 设定步长为0.002,判断是否收敛的条件为1e-10\n",
    "        y = y.reshape(-1,1) #重塑y值的维度以便矩阵运算\n",
    "        [m,d] = np.shape(X) #自变量的维度\n",
    "        self.w = np.zeros((d)) #将参数的初始值定为0\n",
    "        tol = 1e5\n",
    "        #============================= show me your code =======================\n",
    "        while tol > loss:\n",
    "            h_f = X.dot(self.w).reshape(-1,1) \n",
    "            theta = self.w + alpha*np.mean(X*(y - h_f),axis=0) #计算迭代的参数值\n",
    "            tol = np.sum(np.abs(theta - self.w))\n",
    "            self.w = theta\n",
    "        #============================= show me your code =======================\n",
    "    def predict(self, X):\n",
    "        # 用已经拟合的参数值预测新自变量\n",
    "        y_pred = X.dot(self.w)\n",
    "        return y_pred  \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    lr_gd = LR_GD()\n",
    "    lr_gd.fit(x,y)\n",
    "    print(\"估计的参数值为：%s\" %(lr_gd.w))\n",
    "    x_test = np.array([2,4,5]).reshape(1,-1)\n",
    "    print(\"预测值为：%s\" %(lr_gd.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bitb3136b6a1a134bdbbe60830bb16671be"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
